{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3c43bac-e8bd-437d-bf26-8eea956fd921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.OS Error\n",
    "import spacy\n",
    "import os\n",
    "\n",
    "# Download the model first if not available\n",
    "os.system(\"python -m spacy download en_core_web_sm\")\n",
    "\n",
    "# Then load\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f900754-ee0d-4d03-ae98-29e4ff8d1fd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 2.Error: ModuleNotFoundError for TextBlob\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtextblob\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TextBlob\n\u001b[0;32m      3\u001b[0m textblob \u001b[38;5;241m=\u001b[39m TextBlob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTextBlob is amazing.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(blob\u001b[38;5;241m.\u001b[39msentiment)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "# 2.Error: ModuleNotFoundError for TextBlob\n",
    "from textblob import TextBlob\n",
    "textblob = TextBlob(\"TextBlob is amazing.\")\n",
    "print(blob.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3c5848b-5819-4bd6-bdc0-81ee43fa0b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1]\n",
      " [1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# 3.AttributeError                            \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "texts = ['text two', 'text one']  # numeric values instead of strings\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "print(X.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06af0ee4-84c5-4a78-879a-eb6839923366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\BALAJI\n",
      "[nltk_data]     MURUGAN\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad5b9f39-a829-4b5b-b9b0-38055d767e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.81480247 0.57973867 0.        ]\n",
      " [0.         0.57973867 0.81480247]]\n"
     ]
    }
   ],
   "source": [
    "# 5.ValueError                                \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform([\"sentence one\", \"sentence two\"])\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfa8a0f-ac75-45cd-ae0a-3445e7837736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.NameError                                 \n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "wc = WordCloud(stopwords=STOPWORDS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
